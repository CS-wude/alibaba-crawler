#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•çš„æ¨¡å‹éƒ¨ç½²è„šæœ¬
ç”¨äºå°†è®­ç»ƒå¥½çš„èƒ¸éƒ¨Xå…‰ç‰‡åˆ†ç±»æ¨¡å‹éƒ¨ç½²ä¸ºå¯ç”¨çš„é¢„æµ‹å·¥å…·
"""

import os
import sys
import torch
import torch.nn.functional as F
from PIL import Image
import numpy as np
from pathlib import Path
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(__file__))

from model import create_model
from dataset import get_data_transforms

class ChestXRayPredictor:
    """èƒ¸éƒ¨Xå…‰ç‰‡åˆ†ç±»é¢„æµ‹å™¨"""
    
    def __init__(self, model_path, device=None):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        Args:
            model_path: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
            device: è®¡ç®—è®¾å¤‡
        """
        self.device = device or torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model_path = model_path
        self.class_names = ['NORMAL', 'PNEUMONIA']
        
        # åŠ è½½æ¨¡å‹
        self.model = self._load_model()
        
        # è·å–æ•°æ®å˜æ¢
        _, self.transform = get_data_transforms()
        
        print(f"âœ… æ¨¡å‹å·²åŠ è½½åˆ°è®¾å¤‡: {self.device}")
        print(f"âœ… æ¨¡å‹è·¯å¾„: {model_path}")
    
    def _load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            # åˆ›å»ºæ¨¡å‹
            model = create_model(num_classes=2, model_name='resnet50').to(self.device)
            
            # åŠ è½½æƒé‡
            checkpoint = torch.load(self.model_path, map_location=self.device, weights_only=False)
            model.load_state_dict(checkpoint['model_state_dict'])
            
            # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            model.eval()
            
            # æ‰“å°æ¨¡å‹ä¿¡æ¯
            if 'best_acc' in checkpoint:
                print(f"ğŸ“Š æ¨¡å‹è®­ç»ƒæ—¶æœ€ä½³ç²¾åº¦: {checkpoint['best_acc']:.4f}")
            
            return model
            
        except Exception as e:
            raise RuntimeError(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
    
    def predict_single_image(self, image_path, return_probabilities=True):
        """
        é¢„æµ‹å•å¼ å›¾ç‰‡
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            return_probabilities: æ˜¯å¦è¿”å›æ¦‚ç‡
            
        Returns:
            dict: é¢„æµ‹ç»“æœ
        """
        try:
            # åŠ è½½å›¾ç‰‡
            image = Image.open(image_path).convert('RGB')
            original_size = image.size
            
            # é¢„å¤„ç†
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # é¢„æµ‹
            with torch.no_grad():
                outputs = self.model(input_tensor)
                probabilities = F.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
            
            # æ„å»ºç»“æœ
            result = {
                'image_path': str(image_path),
                'image_size': original_size,
                'predicted_class': self.class_names[predicted.item()],
                'confidence': confidence.item(),
                'prediction_time': datetime.now().isoformat()
            }
            
            if return_probabilities:
                result['probabilities'] = {
                    self.class_names[i]: probabilities[0][i].item() 
                    for i in range(len(self.class_names))
                }
            
            return result
            
        except Exception as e:
            return {
                'error': f"é¢„æµ‹å¤±è´¥: {e}",
                'image_path': str(image_path)
            }
    
    def predict_batch(self, image_paths, batch_size=8):
        """
        æ‰¹é‡é¢„æµ‹å¤šå¼ å›¾ç‰‡
        
        Args:
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
            
        Returns:
            list: é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        results = []
        
        for i in range(0, len(image_paths), batch_size):
            batch_paths = image_paths[i:i + batch_size]
            batch_tensors = []
            valid_paths = []
            
            # åŠ è½½å’Œé¢„å¤„ç†æ‰¹æ¬¡å›¾ç‰‡
            for path in batch_paths:
                try:
                    image = Image.open(path).convert('RGB')
                    tensor = self.transform(image)
                    batch_tensors.append(tensor)
                    valid_paths.append(path)
                except Exception as e:
                    results.append({
                        'image_path': str(path),
                        'error': f"åŠ è½½å›¾ç‰‡å¤±è´¥: {e}"
                    })
            
            if not batch_tensors:
                continue
            
            # æ‰¹é‡é¢„æµ‹
            try:
                batch_input = torch.stack(batch_tensors).to(self.device)
                
                with torch.no_grad():
                    outputs = self.model(batch_input)
                    probabilities = F.softmax(outputs, dim=1)
                    confidences, predictions = torch.max(probabilities, 1)
                
                # å¤„ç†ç»“æœ
                for j, path in enumerate(valid_paths):
                    result = {
                        'image_path': str(path),
                        'predicted_class': self.class_names[predictions[j].item()],
                        'confidence': confidences[j].item(),
                        'probabilities': {
                            self.class_names[k]: probabilities[j][k].item() 
                            for k in range(len(self.class_names))
                        }
                    }
                    results.append(result)
                    
            except Exception as e:
                for path in valid_paths:
                    results.append({
                        'image_path': str(path),
                        'error': f"æ‰¹é‡é¢„æµ‹å¤±è´¥: {e}"
                    })
        
        return results
    
    def get_medical_recommendation(self, prediction_result, threshold=0.5):
        """
        æ ¹æ®é¢„æµ‹ç»“æœç»™å‡ºåŒ»å­¦å»ºè®®
        
        Args:
            prediction_result: é¢„æµ‹ç»“æœå­—å…¸
            threshold: åˆ†ç±»é˜ˆå€¼
            
        Returns:
            dict: åŒ»å­¦å»ºè®®
        """
        if 'error' in prediction_result:
            return {'recommendation': 'æ— æ³•ç”Ÿæˆå»ºè®®ï¼Œé¢„æµ‹å¤±è´¥'}
        
        predicted_class = prediction_result['predicted_class']
        confidence = prediction_result['confidence']
        pneumonia_prob = prediction_result.get('probabilities', {}).get('PNEUMONIA', 0)
        
        # ç”Ÿæˆå»ºè®®
        if predicted_class == 'PNEUMONIA':
            if confidence >= 0.9:
                risk_level = 'é«˜é£é™©'
                recommendation = 'å¼ºçƒˆå»ºè®®ç«‹å³å°±åŒ»ï¼Œè¿›è¡Œè¿›ä¸€æ­¥æ£€æŸ¥å’Œæ²»ç–—'
                urgency = 'urgent'
            elif confidence >= 0.7:
                risk_level = 'ä¸­é£é™©'
                recommendation = 'å»ºè®®å°½å¿«å°±åŒ»ï¼Œå’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿæ„è§'
                urgency = 'moderate'
            else:
                risk_level = 'ä½é£é™©'
                recommendation = 'å»ºè®®åŒ»ç–—æœºæ„å¤æŸ¥ï¼Œç»“åˆä¸´åºŠç—‡çŠ¶åˆ¤æ–­'
                urgency = 'low'
        else:  # NORMAL
            if confidence >= 0.9:
                risk_level = 'æ­£å¸¸'
                recommendation = 'å½±åƒæ˜¾ç¤ºæ­£å¸¸ï¼Œå¦‚æœ‰ç—‡çŠ¶è¯·å’¨è¯¢åŒ»ç”Ÿ'
                urgency = 'none'
            elif confidence >= 0.7:
                risk_level = 'åŸºæœ¬æ­£å¸¸'
                recommendation = 'å½±åƒåŸºæœ¬æ­£å¸¸ï¼Œå¦‚æœ‰ä¸é€‚å»ºè®®è§‚å¯Ÿæˆ–å¤æŸ¥'
                urgency = 'low'
            else:
                risk_level = 'ä¸ç¡®å®š'
                recommendation = 'ç»“æœä¸ç¡®å®šï¼Œå»ºè®®ä¸“ä¸šåŒ»ç”Ÿè¿›ä¸€æ­¥è¯„ä¼°'
                urgency = 'moderate'
        
        return {
            'risk_level': risk_level,
            'recommendation': recommendation,
            'urgency': urgency,
            'confidence_interpretation': self._interpret_confidence(confidence),
            'disclaimers': [
                'æœ¬ç»“æœä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç”Ÿè¯Šæ–­',
                'å¦‚æœ‰ç—‡çŠ¶æˆ–æ‹…å¿§ï¼Œè¯·åŠæ—¶å°±åŒ»',
                'æœ€ç»ˆè¯Šæ–­éœ€è¦ç»“åˆä¸´åºŠè¡¨ç°å’Œå…¶ä»–æ£€æŸ¥'
            ]
        }
    
    def _interpret_confidence(self, confidence):
        """è§£é‡Šç½®ä¿¡åº¦å«ä¹‰"""
        if confidence >= 0.95:
            return 'æ¨¡å‹å¯¹æ­¤é¢„æµ‹éå¸¸ç¡®ä¿¡'
        elif confidence >= 0.85:
            return 'æ¨¡å‹å¯¹æ­¤é¢„æµ‹æ¯”è¾ƒç¡®ä¿¡'
        elif confidence >= 0.7:
            return 'æ¨¡å‹å¯¹æ­¤é¢„æµ‹æœ‰ä¸€å®šæŠŠæ¡'
        elif confidence >= 0.6:
            return 'æ¨¡å‹å¯¹æ­¤é¢„æµ‹æŠŠæ¡è¾ƒå°'
        else:
            return 'æ¨¡å‹å¯¹æ­¤é¢„æµ‹ä¸ç¡®å®š'

def create_prediction_report(predictor, image_path, save_path=None):
    """
    åˆ›å»ºå®Œæ•´çš„é¢„æµ‹æŠ¥å‘Š
    
    Args:
        predictor: é¢„æµ‹å™¨å®ä¾‹
        image_path: å›¾ç‰‡è·¯å¾„
        save_path: æŠ¥å‘Šä¿å­˜è·¯å¾„
        
    Returns:
        dict: å®Œæ•´æŠ¥å‘Š
    """
    # è·å–é¢„æµ‹ç»“æœ
    prediction = predictor.predict_single_image(image_path)
    
    if 'error' not in prediction:
        # è·å–åŒ»å­¦å»ºè®®
        medical_advice = predictor.get_medical_recommendation(prediction)
        
        # æ„å»ºå®Œæ•´æŠ¥å‘Š
        report = {
            'report_info': {
                'generated_time': datetime.now().isoformat(),
                'model_version': 'ChestXRay-v1.0',
                'patient_id': f"P{datetime.now().strftime('%Y%m%d%H%M%S')}"
            },
            'image_analysis': prediction,
            'medical_assessment': medical_advice,
            'technical_details': {
                'model_architecture': 'ResNet50',
                'input_size': '224x224',
                'preprocessing': 'ImageNet normalization'
            }
        }
    else:
        report = {
            'error': prediction['error'],
            'generated_time': datetime.now().isoformat()
        }
    
    # ä¿å­˜æŠ¥å‘Š
    if save_path:
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜è‡³: {save_path}")
    
    return report

def batch_process_directory(predictor, input_dir, output_dir=None, file_pattern="*.jpeg"):
    """
    æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„å›¾ç‰‡
    
    Args:
        predictor: é¢„æµ‹å™¨å®ä¾‹
        input_dir: è¾“å…¥ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        file_pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼
    """
    input_path = Path(input_dir)
    if not input_path.exists():
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return
    
    # æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶
    image_files = list(input_path.glob(file_pattern))
    if not image_files:
        print(f"âŒ åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°åŒ¹é…çš„å›¾ç‰‡æ–‡ä»¶")
        return
    
    print(f"ğŸ” æ‰¾åˆ° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    if output_dir:
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
    
    # æ‰¹é‡é¢„æµ‹
    results = predictor.predict_batch(image_files)
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    summary = {
        'total_images': len(image_files),
        'successful_predictions': len([r for r in results if 'error' not in r]),
        'failed_predictions': len([r for r in results if 'error' in r]),
        'class_distribution': {},
        'confidence_statistics': {},
        'processed_time': datetime.now().isoformat()
    }
    
    # ç»Ÿè®¡åˆ†æ
    successful_results = [r for r in results if 'error' not in r]
    if successful_results:
        # ç±»åˆ«åˆ†å¸ƒ
        for class_name in predictor.class_names:
            count = len([r for r in successful_results if r['predicted_class'] == class_name])
            summary['class_distribution'][class_name] = count
        
        # ç½®ä¿¡åº¦ç»Ÿè®¡
        confidences = [r['confidence'] for r in successful_results]
        summary['confidence_statistics'] = {
            'mean': np.mean(confidences),
            'std': np.std(confidences),
            'min': np.min(confidences),
            'max': np.max(confidences)
        }
    
    # ä¿å­˜ç»“æœ
    if output_dir:
        # ä¿å­˜è¯¦ç»†ç»“æœ
        with open(output_path / 'detailed_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜æ±‡æ€»æŠ¥å‘Š
        with open(output_path / 'summary_report.json', 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š ç»“æœå·²ä¿å­˜è‡³: {output_dir}")
    
    # æ‰“å°æ±‡æ€»
    print(f"\nğŸ“‹ æ‰¹é‡å¤„ç†æ±‡æ€»:")
    print(f"   æ€»è®¡å›¾ç‰‡: {summary['total_images']}")
    print(f"   æˆåŠŸé¢„æµ‹: {summary['successful_predictions']}")
    print(f"   å¤±è´¥é¢„æµ‹: {summary['failed_predictions']}")
    
    if summary['class_distribution']:
        print(f"   ç±»åˆ«åˆ†å¸ƒ:")
        for class_name, count in summary['class_distribution'].items():
            percentage = count / summary['successful_predictions'] * 100
            print(f"     {class_name}: {count} ({percentage:.1f}%)")
    
    return results, summary

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºé¢„æµ‹å™¨çš„ä½¿ç”¨"""
    import argparse
    
    parser = argparse.ArgumentParser(description='èƒ¸éƒ¨Xå…‰ç‰‡åˆ†ç±»é¢„æµ‹å·¥å…·')
    parser.add_argument('--model', type=str, default='checkpoints/best_model.pth',
                       help='æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--image', type=str, help='å•å¼ å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--batch', type=str, help='æ‰¹é‡å¤„ç†ç›®å½•è·¯å¾„') 
    parser.add_argument('--output', type=str, help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--report', action='store_true', help='ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not os.path.exists(args.model):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        print("è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–æ£€æŸ¥æ–‡ä»¶è·¯å¾„")
        return
    
    # åˆ›å»ºé¢„æµ‹å™¨
    try:
        predictor = ChestXRayPredictor(args.model)
    except Exception as e:
        print(f"âŒ åˆ›å»ºé¢„æµ‹å™¨å¤±è´¥: {e}")
        return
    
    # å•å¼ å›¾ç‰‡é¢„æµ‹
    if args.image:
        if not os.path.exists(args.image):
            print(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {args.image}")
            return
        
        print(f"\nğŸ” æ­£åœ¨åˆ†æå›¾ç‰‡: {args.image}")
        
        if args.report:
            # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
            report_path = args.output or f"prediction_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            report = create_prediction_report(predictor, args.image, report_path)
            
            print(f"\nğŸ“‹ é¢„æµ‹æŠ¥å‘Š:")
            if 'error' not in report:
                print(f"   é¢„æµ‹ç±»åˆ«: {report['image_analysis']['predicted_class']}")
                print(f"   ç½®ä¿¡åº¦: {report['image_analysis']['confidence']:.4f}")
                print(f"   é£é™©ç­‰çº§: {report['medical_assessment']['risk_level']}")
                print(f"   åŒ»å­¦å»ºè®®: {report['medical_assessment']['recommendation']}")
            else:
                print(f"   é”™è¯¯: {report['error']}")
        else:
            # ç®€å•é¢„æµ‹
            result = predictor.predict_single_image(args.image)
            
            print(f"\nğŸ“‹ é¢„æµ‹ç»“æœ:")
            if 'error' not in result:
                print(f"   é¢„æµ‹ç±»åˆ«: {result['predicted_class']}")
                print(f"   ç½®ä¿¡åº¦: {result['confidence']:.4f}")
                print(f"   æ¦‚ç‡åˆ†å¸ƒ:")
                for class_name, prob in result['probabilities'].items():
                    print(f"     {class_name}: {prob:.4f}")
            else:
                print(f"   é”™è¯¯: {result['error']}")
    
    # æ‰¹é‡å¤„ç†
    elif args.batch:
        print(f"\nğŸ” æ‰¹é‡å¤„ç†ç›®å½•: {args.batch}")
        batch_process_directory(predictor, args.batch, args.output)
    
    else:
        print("è¯·æŒ‡å®š --image æˆ– --batch å‚æ•°")
        print("\nä½¿ç”¨ç¤ºä¾‹:")
        print("  å•å¼ å›¾ç‰‡: python deploy_simple.py --image path/to/image.jpg")
        print("  è¯¦ç»†æŠ¥å‘Š: python deploy_simple.py --image path/to/image.jpg --report")
        print("  æ‰¹é‡å¤„ç†: python deploy_simple.py --batch path/to/images/ --output results/")

if __name__ == "__main__":
    main() 